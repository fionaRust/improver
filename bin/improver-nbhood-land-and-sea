#!/usr/bin/env python
# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# (C) British Crown Copyright 2017 Met Office.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its
#   contributors may be used to endorse or promote products derived from
#   this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
"""Script to run neighbourhooding processing over areas of land and sea
separately before combining them to return unified fields. Topographic zones
may also be employed, with the sea area being treated as a distinct zone."""

import numpy as np

import iris
from improver.argparser import ArgParser

from improver.nbhood.use_nbhood import (
    ApplyNeighbourhoodProcessingWithAMask,
    CollapseMaskedNeighbourhoodCoordinate)
from improver.nbhood.nbhood import NeighbourhoodProcessing
from improver.utilities.load import load_cube
from improver.utilities.cube_manipulation import merge_cubes


def apply_clipping(cube, result):
    """A temporary fix to clip data values that are artificially enlarged
    by the neighbourhooding process.

    Args:
       cube (iris.cube.Cube):
          The cube that was passed to the CLI.
       result (iris.cube.Cube):
          The cube that has undergone neighbourhooding and is to be clipped.
    """
    input_max = cube.data.max()
    input_min = cube.data.min()
    result.data = np.clip(result.data, input_min, input_max)


def main():
    """Load in arguments for applying neighbourhood processing when using a
    mask."""
    parser = ArgParser(
        description='Neighbourhood the input cube as two distinct regions of '
        'land and sea, as defined by the mask (INPUT_MASK). The resulting '
        'cube will include the two independently neighbourhooded regions '
        'stitched back together. An optional secondary mask may be provided'
        ' (ADDITIONAL_MASK) with an additional coordinate (e.g. topographic_'
        'zone) over which to iterate. If provdided this CLI will neighbourhood'
        ' the data in each of these masked regions over the "masked in" area '
        'in the INPUT_MASK. These multiple regions of masking will be '
        'collapsed using the weights provided, and any areas spreading beyond '
        'the INPUT_MASK will be re-masked. Again, the sea area will finally '
        'be stitched around the land area in the final output.')

    parser.add_argument('input_filepath', metavar='INPUT_FILE',
                        help='A path to an input NetCDF file to be processed.')
    parser.add_argument('input_mask_filepath', metavar='INPUT_MASK',
                        help=('A path to an input NetCDF land mask file.'))
    parser.add_argument('output_filepath', metavar='OUTPUT_FILE',
                        help='The output path for the processed NetCDF.')

    mask_group = parser.add_argument_group(
        'Addtional Mask - All args are required to use an additional mask')
    mask_group.add_argument('--additional_mask_filepath',
                            metavar='ADDITIONAL_MASK',
                            help='A path to an additional input mask NetCDF '
                            'file to be used as well as the land-sea '
                            'discrimination provided by the land mask.')
    mask_group.add_argument('--coord_for_masking', metavar='COORD_FOR_MASKING',
                            help='Coordinate to iterate over when applying '
                            'the additional mask to the neighbourhood '
                            'processing. ')
    mask_group.add_argument('--weights_for_collapsing_dim', metavar='WEIGHTS',
                            default=None,
                            help='A path to an weights NetCDF file containing '
                            'the weights which are used for collapsing the '
                            'dimension gained through masking.')

    radius_group = parser.add_argument_group(
        'Neighbourhooding Radius - Set only one of the options')
    group = radius_group.add_mutually_exclusive_group()
    group.add_argument('--radius', metavar='RADIUS', type=float,
                       help='The radius (in m) for neighbourhood processing.')
    group.add_argument('--radii-by-lead-time',
                       metavar=('RADII_BY_LEAD_TIME', 'LEAD_TIME_IN_HOURS'),
                       nargs=2,
                       help='The radii for neighbourhood processing '
                       'and the associated lead times at which the radii are '
                       'valid. The radii are in metres whilst the lead time '
                       'has units of hours. The radii and lead times are '
                       'expected as individual comma-separated lists with '
                       'the list of radii given first followed by a list of '
                       'lead times to indicate at what lead time each radii '
                       'should be used. For example: 10000,12000,14000 1,2,3 '
                       'where a lead time of 1 hour uses a radius of 10000m, '
                       'a lead time of 2 hours uses a radius of 12000m, etc.')

    parser.add_argument('--ens_factor', metavar='ENS_FACTOR', type=float,
                        default=1.0,
                        help='The factor with which to adjust the '
                        'neighbourhood size for more than one '
                        'ensemble member. If ens_factor = 1.0 this '
                        'essentially conserves ensemble members if '
                        'every grid square is considered to be the '
                        'equivalent of an ensemble member.'
                        'Optional, defaults to 1.0.')
    parser.add_argument('--sum_or_fraction', default="fraction",
                        choices=["sum", "fraction"],
                        help='The neighbourhood output can either be in the '
                             'form of a sum of the neighbourhood, or a '
                             'fraction calculated by dividing the sum of the '
                             'neighbourhood by the neighbourhood area. '
                             '"fraction" is the default option.')
    parser.add_argument('--no_clip', action='store_true', default=False,
                        help="By default the results of neighbourhooding will "
                             "be clipped to the extremes in the input data. "
                             "If '--no_clip' is used then this clipping is "
                             "turned off. "
                             "Once the neighbourhood code is fixed so it "
                             "doesn't produce values above or below the "
                             "extremes in the input data this option can be "
                             "removed.")

    args = parser.parse_args()

    cube = load_cube(args.input_filepath)
    cube = cube[0]

    landmask = load_cube(args.input_mask_filepath)
    # Create land and sea masks
    land_only = landmask.copy(data=landmask.data.astype(int))
    sea_only = landmask.copy(data=np.logical_not(landmask.data).astype(int))

    if args.radius:
        radius_or_radii = args.radius
        lead_times = None
    elif args.radii_by_lead_time:
        radius_or_radii = args.radii_by_lead_time[0].split(",")
        lead_times = args.radii_by_lead_time[1].split(",")

    if args.additional_mask_filepath:
        additional_mask = load_cube(args.additional_mask_filepath)
        weights = load_cube(args.weights_for_collapsing_dim)

        mask_cube = iris.cube.CubeList()
        xy_slices = additional_mask.slices([cube.coord(axis='y'),
                                            cube.coord(axis='x')])
        for xy_slice in xy_slices:
            mask_cube.append(xy_slice.copy(data=np.logical_and(
                land_only.data, xy_slice.data).astype(int)))

        mask_cube = merge_cubes(mask_cube)

        result_land = ApplyNeighbourhoodProcessingWithAMask(
            args.coord_for_masking, radius_or_radii, lead_times=lead_times,
            ens_factor=args.ens_factor, sum_or_fraction=args.sum_or_fraction,
            re_mask=True).process(cube, mask_cube)
    else:
        result_land = NeighbourhoodProcessing(
            'square', radius_or_radii, lead_times=lead_times,
            ens_factor=args.ens_factor, sum_or_fraction=args.sum_or_fraction,
            re_mask=True).process(cube, land_only)

    result_sea = NeighbourhoodProcessing(
        'square', radius_or_radii, lead_times=lead_times,
        ens_factor=args.ens_factor, sum_or_fraction=args.sum_or_fraction,
        re_mask=True).process(cube, sea_only)

    result_land.data = np.ma.masked_invalid(result_land.data)
    result_sea.data = np.ma.masked_invalid(result_sea.data)
    iris.save(result_land, 'land_result.nc')
    iris.save(result_sea, 'sea_result.nc')

    # TODO: This clip should be removed once the neighbourhood code is fixed.
    # At the moment the neighbourhood code can produce values beyond extremes
    # in the input data.
    if not args.no_clip:
        apply_clipping(cube, result_land)
        apply_clipping(cube, result_sea)

    if args.additional_mask_filepath:
        # Collapse with the masking dimension.
        result_land = CollapseMaskedNeighbourhoodCoordinate(
            args.coord_for_masking, weights=weights).process(result_land)

    # Recombine cubes to be a single output.
    combined_data = np.ma.array(
        result_land.data.filled(1) * result_sea.data.filled(1),
        mask=(result_land.data.mask * result_sea.data.mask))
    result = result_land.copy(data=combined_data)

    iris.save(result, args.output_filepath)


if __name__ == "__main__":
    main()
